{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import config as cfg\n",
    "from dust3r.model import AsymmetricCroCo3DStereo \n",
    "import logging \n",
    "from dust3r.demo import get_reconstructed_scene, get_reconstructed_scene_with_known_poses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Define the output format\n",
    ")\n",
    "\n",
    "device = cfg.DEVICE \n",
    "weights_path = cfg.MODEL_PATH   \n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(weights_path).to(device)\n",
    "img_size = cfg.IMAGE_SIZE\n",
    "\n",
    "# Log the device, and model path\n",
    "logging.info(f\"Device: {device}\")\n",
    "logging.info(f\"Model Path: {weights_path}\")\n",
    "\n",
    "# Output directory\n",
    "import datetime \n",
    "date_as_string = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = cfg.OUTPUT_DIR + \"/\" + date_as_string\n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "logging.info(f\"Output Directory: {output_dir}\")\n",
    "\n",
    "# Data directory\n",
    "data_dir = cfg.DATA_DIR\n",
    "logging.info(f\"Data Directory: {data_dir}\")\n",
    "filelist = os.listdir(data_dir) #return full path\n",
    "filelist = [os.path.join(data_dir, x) for x in filelist]\n",
    "logging.info(f\"Filelist: {filelist}\")\n",
    "print(\"cfg.KNOWN_POSES\", cfg.KNOWN_POSES)\n",
    "print(\"Lenght of knownposes\", len(cfg.KNOWN_POSES))\n",
    "\n",
    "\n",
    "# Get the reconstructed scene\n",
    "scene, outfile, imgs = get_reconstructed_scene_with_known_poses(\n",
    "                            output_dir, model, device, cfg.SILENT, img_size, filelist, cfg.SCHEDULE,\n",
    "                            cfg.NITER, cfg.MIN_CONF_THR, cfg.AS_POINTCLOUD, cfg.MASK_SKY,\n",
    "                            cfg.CLEAN_DEPTH, cfg.TRANSPARENT_CAMS, cfg.CAM_SIZE, cfg.SCENEGRAPH_TYPE,\n",
    "                            cfg.WINSIZE, cfg.REFID, cfg.KNOWN_POSES, cfg.KNOWN_FOCALS)\n",
    "\n",
    "\n",
    "# scene, outfile, imgs = get_reconstructed_scene(\n",
    "#                             output_dir, model, device, cfg.SILENT, img_size, filelist, cfg.SCHEDULE,\n",
    "#                             cfg.NITER, cfg.MIN_CONF_THR, cfg.AS_POINTCLOUD, cfg.MASK_SKY,\n",
    "#                             cfg.CLEAN_DEPTH, cfg.TRANSPARENT_CAMS, cfg.CAM_SIZE, cfg.SCENEGRAPH_TYPE,\n",
    "#                             cfg.WINSIZE, cfg.REFID)\n",
    "\n",
    "\n",
    "\n",
    "# Output is .glb file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"images shape\", len(imgs))\n",
    "print(\"First set of images shape\", imgs[0].shape, imgs[1].shape, imgs[2].shape, imgs[3].shape, imgs[4].shape, imgs[5].shape)\n",
    "num_images = int(len(imgs)/3)\n",
    "for i in range(num_images):\n",
    "    ## Visualize the image, depth and confidence maps  at 3n-2, 3n-2, 3n indices\n",
    "    img = imgs[3*i]\n",
    "    depth = imgs[3*i+1]\n",
    "    confidence = imgs[3*i+2]\n",
    "    # Print max value in the depth map \n",
    "    print(\"Max value in the depth map\", depth.max())\n",
    "    print(\"Min value in the depth map\", depth.min())    \n",
    "    print(f\"Image {i}\")\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Depth shape: {depth.shape}\")\n",
    "    print(f\"Confidence shape: {confidence.shape}\")\n",
    "    print(\"\\n\")\n",
    "    # Visualize the image, depth and confidence maps in a single plot \n",
    "    fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(depth)\n",
    "    ax[1].set_title(\"Depth\")\n",
    "    ax[2].imshow(confidence)\n",
    "    ax[2].set_title(\"Confidence\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Visualize the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scene\", scene.get_im_poses())\n",
    "print(\"Scene\", scene.get_im_poses().shape)\n",
    "pose1 = scene.get_im_poses()[0] \n",
    "pose2 = scene.get_im_poses()[1]\n",
    "# Find relative pose between two cameras \n",
    "def relative_pose(pose1, pose2):\n",
    "    ''' \n",
    "    4*4 pose matrix of camera 1 and camera 2\n",
    "    return the relative pose between camera 1 and camera 2 \n",
    "    '''\n",
    "    poseR1 = pose1[:3,:3]\n",
    "    poseR2 = pose2[:3,:3]\n",
    "    poseT1 = pose1[:3,3]\n",
    "    poseT2 = pose2[:3,3]\n",
    "    relative_pose = pose2\n",
    "    relative_pose[:3,:3] = poseR1.T @ poseR2\n",
    "    relative_pose[:3,3] = poseT2 - poseT1\n",
    "    return relative_pose\n",
    "\n",
    "relative_pose = relative_pose(pose1, pose2)\n",
    "print(\"Relative Pose\", relative_pose)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_translation_rotation(matrix):\n",
    "\n",
    "    try:\n",
    "        matrix = matrix.detach().cpu().numpy()  # Move to CPU and convert to NumPy array\n",
    "    except:\n",
    "        # If the matrix is already a NumPy array\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Extract translation (last column)\n",
    "    translation = matrix[:3, 3]\n",
    "    translation = np.linalg.norm(translation)  # Compute the norm of the translation vector\n",
    "    \n",
    "    # Extract rotation (top-left 3x3 submatrix)\n",
    "    rotation_matrix = matrix[:3, :3]\n",
    "    \n",
    "    # Convert rotation matrix to Euler angles (yaw, pitch, roll)\n",
    "    yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])  # Yaw (Z-axis)\n",
    "    pitch = np.arcsin(-rotation_matrix[2, 0])  # Pitch (Y-axis)\n",
    "    roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])  # Roll (X-axis)\n",
    "    # Convert angles to degrees\n",
    "    yaw = np.degrees(yaw)\n",
    "    pitch = np.degrees(pitch)\n",
    "    roll = np.degrees(roll)\n",
    "    \n",
    "    \n",
    "    return translation, yaw, pitch, roll\n",
    "\n",
    "# Extract translation and rotation from the relative pose\n",
    "relative_translation, relative_yaw, relative_pitch, relative_roll = extract_translation_rotation(relative_pose)\n",
    "print(\"Relative Translation\", relative_translation)\n",
    "print(\"Relative Yaw\", relative_yaw)\n",
    "print(\"Relative Pitch\", relative_pitch)\n",
    "print(\"Relative Roll\", relative_roll)\n",
    "\n",
    "\n",
    "# Test by transforming the pose1 to pose2\n",
    "pose1_transformed = relative_pose @ pose1\n",
    "print(\"Pose1 transformed\", pose1_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_relative_pose_rgb_l = [[ 0.99339134 -0.05150564  0.10257099 -0.00428072]\n",
    "#  [ 0.10364322  0.78649219 -0.60884162 -0.01184173]\n",
    "#  [-0.04931251  0.61544878  0.78663275 -0.00511398]\n",
    "#  [ 0.          0.          0.          1.        ]]\n",
    "\n",
    "# gt_relative_pose_r_l = [[ 0.99836471 -0.03532317  0.04494634  0.00567676]\n",
    "#  [ 0.05208901  0.23820291 -0.96981757 -0.11215309]\n",
    "#  [ 0.02355068  0.97057285  0.23965332 -0.08683892]\n",
    "#  [ 0.          0.          0.          1.        ]]\n",
    "import numpy as np\n",
    "gt_relative_pose_r_l = np.array([[ 0.99836471, -0.03532317,  0.04494634,  0.00567676],\n",
    "    [ 0.05208901,  0.23820291, -0.96981757, -0.11215309],\n",
    "    [ 0.02355068,  0.97057285,  0.23965332, -0.08683892],\n",
    "    [ 0.,          0.,          0.,          1.        ]])\n",
    "\n",
    "gt_relative_translation, gt_relative_yaw, gt_relative_pitch, gt_relative_roll = extract_translation_rotation(gt_relative_pose_r_l)\n",
    "print(\"GT Relative Translation\", gt_relative_translation)\n",
    "print(\"GT Relative Yaw\", gt_relative_yaw)\n",
    "print(\"GT Relative Pitch\", gt_relative_pitch)\n",
    "print(\"GT Relative Roll\", gt_relative_roll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_poses = [[[1.0, 0.0, 0.0, 0.0],\n",
    "               [0.0, 1.0, 0.0, 0.0],\n",
    "               [0.0, 0.0, 1.0, 0.0],\n",
    "               [0.0, 0.0, 0.0, 1.0]], \n",
    "                [[0.99339134, -0.05150564,  0.10257099, -0.00428072],\n",
    "                [ 0.10364322,  0.78649219, -0.60884162, -0.01184173],\n",
    "                [-0.04931251,  0.61544878,  0.78663275, -0.00511398],\n",
    "                [ 0.0, 0.0, 0.0, 1.0]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Load the .glb file\n",
    "mesh = o3d.io.read_triangle_mesh(\"temp_test/2025-02-11_02-18-41/scene.glb\")\n",
    "\n",
    "\n",
    "# Visualize the .glb file\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
